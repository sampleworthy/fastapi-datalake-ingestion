# FastAPI + Azure Data Lake Ingestion

This app shows how to:
- Accept POSTed JSON using FastAPI + Pydantic
- Validate schema with Pydantic
- Store data in Azure Data Lake Gen2

### Run Locally
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
./run.sh

### âš¡ FastAPI Azure Data Lake Ingestion Service
This project demonstrates a scalable, cloud-native ingestion service built with FastAPI, Pydantic, and Azure Data Lake Gen2.

Designed for enterprise data engineering use casesâ€”like those seen in Accenture client engagementsâ€”this service enables:

âœ… Secure ingestion of external JSON payloads via REST API

âœ… Schema validation using Pydantic

âœ… Raw data storage in Azure Data Lake Gen2

âœ… IaC deployment via Terraform (resource group, storage, filesystem)

âœ… Containerization using Docker & Docker Compose

This architecture fits cleanly into modern data platforms built on Azure, providing a clean staging point for downstream analytics in Synapse, Databricks, or Power BI.

ğŸ”§ Tech Stack: FastAPI Â· Python Â· Azure Storage SDK Â· Terraform Â· Docker
ğŸŒ Use Case: Multi-vendor JSON ingestion for enterprise data lake systems
ğŸ“¦ Deployable: Locally via Docker or to Azure Web App Containers

ğŸ‘·â€â™‚ï¸ Built for real-world client environments like those served by Accentureâ€™s Intelligent Platform Services team.
